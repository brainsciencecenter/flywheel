#!/bin/bash

CmdName=$(basename "$0")
syntax="${CmdName} {-t a|c|g|j} [-F] [-f {Compute|Core|Ram|Storage|Bucket|Coldline} ] [-g] [-n line[[,line]...] [-v] file"

# c = Cost Table
# j = Jobs Report
# g = GCP cost allocation
# a = Flywheel usage allocation report

# Compute
# Instance Core
# Storage
# Buckets
# Coldline

# Print all of foo
#	 verify foo
# Print first line of foo
# 	verify -n 1p foo
# Print first line of foo twice
# 	verify -n '1p;1p' foo
# Print first line of foo, then lines 2-5 twice
# 	verify -n '1p;2,5p;2,5p' foo
# Warning:
#       verify -n '1p;2p;2p;1p' foo
# gives line 1 twice, then line 2 twice, not line 1, line 2, line 2, line 1

# *** should have a warning on Usage where different units are being combined

function getHeaderIndicies() {
    InputFile="$1"
    shift

    RegEx=""
    for i in "$@"
    do
	RegEx="${RegEx}|($i)"
    done
    RegEx="$(echo $RegEx | sed 's/^|//')"
    echo $RegEx 1>&2

    head -n 1 "$InputFile" | tr ',' '\012' | grep -P -n "^($RegEx)$" | cut -f 1 -d : | (tr '\012' ',';echo) | sed 's/,$//'
}


#
# SliceNDice does not want a header line
#
function sliceNDice {
    local Fields
    local InputFile="$1"

	 case "$opt_t" in
	      a)
		  # Pull days, group, project_label, session_count,total-compute_ms, total_job_count, total_storage_bytes
		  Fields=4,5,10,11,12,13,14
		  csvcut -c "$Fields" | awk -F , '{ if ($3 != "") {print $0} }'
		  ;;

	      g)
		  # Pull Group, Project name, Project ID, Service description, SKU description, Usage amount, Usage unit, Cost ($)
		  Fields=3,4,5,6,8,13,14,15
		  csvcut -c "$Fields" | grep -v -i Promotions | grep -v -i Discount | grep -v '^,,' 
		  ;;
	      c)
		  Fields=$(getHeaderIndicies "$InputFile" "Project ID" "Service description" "SKU description" "Usage amount" "Usage unit" "Cost \(\\\$\)")

		  csvcut -c "$Fields" | grep -v -i Promotions | grep -v -i Discount | grep -v '^,,' 
		  ;;

	      j)
		  # gear_name,job_origin_id,job_state,job_elapsed_time_ms,gcp_cpus,gcp_compute_percent,initial_analysis,group,project,gcp_compute_cost
		  Fields=4,7,9,10,13,14,15,16,17,23
		  csvcut -c "$Fields"
		  ;;
		  
	 esac

}

function total {
    local Fields
    
    if [ -n "$opt_v" ]
    then
	cat
    else
	
	case "$opt_t" in
	    a)
		Fields=1,4,5,6,7
		if [ -n "$1" ]
		then
		    units=gibibytes
		    if [ -n "$opt_g" ]
		    then
			units=gigabytes
		    fi
		    
		    csvcut -c "$Fields" | sed 's/days,//; s/total_compute_ms/total_compute_hours/; s/byte_day/'"$units"'/'
		else
		    ByteDenominator="1024.0/1024.0/1024.0"
		    if [ -n "$opt_g" ]
		    then
			ByteDenominator="1000.0/1000.0/1000.0"
		    fi
		    HourDenominator="1000.0/3600.0"
		    csvcut -c "$Fields" | awk -F , 'BEGIN { Sessions = 0.0; MS = 0.0; Jobs = 0.0; Bytes = 0.0;} { Sessions = Sessions + $2; MS = MS + $3; Jobs = Jobs + $4; Bytes = Bytes + ($5 / $1); } END { printf("%.2f,%.2f,%.2f,%.2f\n",Sessions, MS/'"$HourDenominator"', Jobs, Bytes/'"$ByteDenominator"'); }'
		fi
		
		;;

	    c)
		Fields=4,6
		if [ -n "$1" ]
		then
		    csvcut -c "$Fields"
		else
		    csvcut -c "$Fields" | awk -F , 'BEGIN {Usage = 0.0; Cost = 0.0;} { Usage = Usage + $1; Cost = Cost + $2; } END {printf("%.2f,%.2f\n",Usage,Cost) }'
		fi
		
		;;

	    g)
		Fields=6,8
		if [ -n "$1" ]
		then
		    csvcut -c "$Fields"
		else
		    csvcut -c "$Fields" | awk -F , 'BEGIN {Usage = 0.0; Cost = 0.0;} { Usage = Usage + $1; Cost = Cost + $2; } END {printf("%.2f,%.2f\n",Usage,Cost) }'
		fi
		;;
		
	    j)
		Fields=3,4,5,6,7,10
		if [ -n "$1" ]
		then
		    csvcut -c "$Fields" | sed 's/job_state/job_count/; s/job_elapsed_time_ms,gcp_cpus/gcp_compute_hours/'
		else
		    csvcut -c "$Fields" | awk -F , 'BEGIN {JobCount = 0.0;  MS = 0.0; GCPPercent = 0.0; InitialAnalysis = 0.0; GCPComputeCost = 0.0;} {if ($1 == "complete") {JobCount = JobCount + 1}; MS = MS + $2 * $3; GCPPercent = GCPPercent + $4; if ($5 == "True" || $5 == "TRUE") {InitialAnalysis = InitialAnalysis + 1}; GCPCost = GCPCost + $6; } END { printf("%d,%.2f,%.2f,%d,%.2f\n",JobCount,MS/1000.0/3600.0,GCPPercent,InitialAnalysis,GCPCost); }'
		fi
		;;

	esac
    fi
    
}

#
# Removed internal commas and unquotes fields
#  a,b,"1,234",c => a,b,1234,c
#
function deCommafie {
	 # From https://unix.stackexchange.com/questions/48672/remove-comma-between-the-quotes-only-in-a-comma-delimited-file
	 awk -F'"' -v OFS='' '{ for (i=2; i<=NF; i+=2) gsub(",", "", $i) } 1'
}

function allOrFlywheel {
    # the regex is after the first set of csvcut in sliceNDice
    if [ "$opt_t" == c ]
    then
	RegEx='^upenn-flywheel,'
    else
	RegEx=',upenn-flywheel,'
    fi
    
    if [ -n "$opt_F" ]
    then
	grep "$RegEx"
    else
	cat
    fi
}

function filter {
    case "$opt_t" in
	c|g)
	    case "$opt_f" in
		Compute)
		    allOrFlywheel | grep 'Compute Engine'
		    ;;
		Core)
		    allOrFlywheel | grep 'Compute Engine' | grep 'Instance Core'
		    ;;
		Ram)
		    allOrFlywheel | grep 'Compute Engine' | grep 'Instance Ram'
		    ;;
		Storage)
		    allOrFlywheel | grep 'Cloud Storage'
		    ;;
		Bucket*)
		    allOrFlywheel | grep 'Cloud Storage' | grep 'Standard Storage' 
		    ;;
		Coldline)
		    allOrFlywheel | grep 'Cloud Storage' | grep Coldline | grep Multi
		    ;;

		*)
		    allOrFlywheel
	    esac
	    ;;

	a|j)
	    grep "$opt_f"
	    ;;
	*)
	    cat
	    ;;
    esac
}

opt_n='2,$p'

while getopts Ff:gn:t:v arg
do
	case "$arg" in
	     F|f|g|t|v)
		 eval "opt_${arg}='${OPTARG:=1}'"
		;;
	     n)
		 opt_n="${OPTARG}"
		 ;;
	esac
done


shift $(($OPTIND - 1))

SourceFile="$1"

head -n 1 "$SourceFile" | sliceNDice "$SourceFile" | total "header"

sed -n "${opt_n}" "$SourceFile" | sliceNDice "$SourceFile" | deCommafie | filter | total
